---
title: "DB공부를 해보자(데이터베이스 핵심 원리)"
date: 2025-08-12 21:00:00 +0900
categories: [CS]
tags: [DB, Optimizer, Index, Transaction]
---

## DB 공부를 하기로 마음먹은 이유

저는 비전공자로서 개발자를 지망하면서 집중한 부분이 두가지였습니다.
1. 알고리즘
   - 면접 기회를 얻기 위해서는 코딩테스트를 통과할 실력이 되어야합니다. 그렇기에 알고리즘만큼은 어떤 문제를 마주하여도 자신있게 풀 실력이 되어야한다고 생각했습니다. 심지어 알고리즘은 저에게 너무 재미있는 분야라 여전히 꾸준히, 그리고 열정적으로 공부하고 있습니다.
2. 운영체제
   - 몇 번의 면접을 경험하며, 느낀 점이 있습니다. 기본적인 컴퓨터 구조와 운영체제에 대한 지식을 필요로 한다는 것입니다. 특히 제조업 쪽 대기업에서 시스템 개발자를 하기 위해서는 반드시 알아야하는 부분이죠. 그렇기에 운영체제에 대한 공부를 지난 몇 달동안 열심히 했습니다. 책도 읽고, 라즈베리파이로 리눅스 서버를 구축하고 그 안에서 커널 레벨의 동작도 공부하고 있습니다.

사실, 네트워크와 데이터베이스는 저에게 차순위였습니다. 특히 데이터베이스는 이미 최적화가 잘 되어있고, AI를 통해 쿼리를 짜면 그만이라는 생각을 했습니다. 하지만, 이제 DB를 공부해야겠다는 생각이 들어 시작하고자합니다. 그 이유로는 두 가지 정도 들 수 있겠습니다.

1. **DB설계 능력을 기르고자.**
   - 프로젝트를 하다보면, 많은 양의 테이블과 컬럼들을 설계합니다. 하지만, 이때 DB에 대한 이해가 부족하여 프로젝트를 진행하며 스키마를 자주 바꾸게 됩니다. 하나의 테이블을 수정하면, 그와 관련된 테이블까지 수정해야하는 경우가 비일비재합니다. 그렇게 되면, 구현한 API까지도 수정하게 되는 대참사도 발생하고는 합니다. 작업의 효율성을 위해서 DB설계 능력은 필수적이라는 생각이 듭니다.
2. **시스템의 성능을 올리고자.**
   - 알고리즘 문제를 생각해볼까요. 모든 문제는 브루트포스로 풀 수 있습니다. 하지만, 자료의 크기가 커지면 고급 알고리즘을 통해 최적화를 진행해야합니다. 시스템도 마찬가지 입니다. 단순히 원하는 데이터를 처리하는 것만으로는 부족합니다. 대규모 시스템에서, 방대한 양의 데이터를 효율적으로 처리하기 위해서는 DB에 대한 이해가 필수적입니다. 

이러한 이유에서 저는 DB공부를 해야겠다는 생각을 했고, 오늘은 그 공부의 첫 내용인 데이터베이스 시스템의 핵심 원리 이해를 다루고자 합니다.

목차는 다음과 같습니다.

1.  저장소와 데이터 구조 (Storage & Data Structures)
2.  인덱스 (Indexes)
3.  쿼리 실행 엔진과 옵티마이저 (Query Executor & Optimizer)
4.  트랜잭션과 동시성 제어 (Transactions & Concurrency)

하나의 글로 다루기에 정말 많은 양일 수 있습니다. 하지만, 제가 이해한 과정을 최대한 일목요연하게 정리하여 도움이 되도록 작성하겠습니다.

## 1. 저장소와 데이터 구조 (Storage & Data Structures)

알고리즘을 공부하며 익숙하게 접했던 트리(Tree) 구조가 이곳에서 다시 등장합니다. 데이터베이스는 수많은 데이터를 단순히 파일에 기록하는 것이 아니라, 빠르고 효율적인 탐색을 위해 **B+ Tree**라는 자료구조를 사용합니다. B+Tree를 다루기 전에, B Tree가 궁금하신 분들은 [이진탐색이 섹시한 이유]({% post_url 2025-07-14-why-binary-search %}) 해당 포스트를 보고오시면 좋을 듯 합니다.

아마 "왜 이진 탐색 트리(BST)가 아닐까?"라는 의문이 드실 수 있습니다. 핵심은 데이터베이스가 **디스크(Disk)**에 데이터를 저장한다는 점입니다. 메모리에 비해 현저히 느린 디스크의 접근(I/O) 횟수를 최소화하는 것이 DB 성능의 관건입니다. BST는 데이터가 많아질수록 트리의 높이가 깊어져 디스크 접근 횟수가 늘어나는 반면, B+ Tree는 하나의 노드(Node)에 수백 개의 자식 노드 포인터를 저장하여 트리의 높이를 극단적으로 낮춥니다. 덕분에 수억 건의 데이터도 단 3~4번의 디스크 I/O만으로 원하는 데이터를 찾아낼 수 있습니다.

> #### B+ Tree의 핵심 전략
> 1.  하나의 노드에 많은 Key를 저장하여 **트리의 높이를 낮춘다.** (탐색 시 디스크 접근 횟수 감소)
> 2.  리프 노드(Leaf Node)끼리 연결 리스트로 연결하여 **범위 검색(`WHERE price > 10000`) 성능을 높인다.**

물론 B+ Tree 외에도 다른 방식의 인덱스가 존재합니다. 바로 해시 인덱스입니다.

### 해시 인덱스 (Hash Index)

해시 인덱스는 이름 그대로 해시 테이블(Hash Table) 자료구조를 사용하여, 이론적으로 $O(1)$이라는 매우 빠른 시간 복잡도로 데이터를 찾아냅니다. 하지만 특정 상황에서만 강력한 힘을 발휘하는 명확한 한계를 가집니다.

해시 인덱스는 '주민등록번호'나 '이메일 주소'처럼, 항상 값이 정확히 일치하는 조건으로만 검색할 때 최고의 성능을 발휘합니다. 하지만 조금이라도 범위(나이가 30 이상)나 순서(최신 가입 순)가 필요한 쿼리에는 전혀 힘을 쓰지 못합니다.

반면, **B+ Tree**는 등호(=) 비교에서도 매우 빠를 뿐만 아니라, 데이터베이스의 빈번한 요구사항인 범위 검색과 정렬까지 완벽하게 지원하는 **만능형 인덱스**입니다.

| 비교 항목       | Hash Index (해시 인덱스)                                                                                                                                                                                                                       | B+ Tree (B+ 트리 인덱스)                                                |
| :-------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------- |
| **최적 상황**   | 등호(=) 비교, `IN` 절을 사용한 조회<br>Key 값을 정확히 알고 있는 경우에 가장 빠름.                                                                                                                                                             | 범위(Range) 검색 (`>`, `<`, `BETWEEN`)<br>등호(=) 비교에도 충분히 빠름. |
| **시간 복잡도** | 평균 $O(1)$                                                                                                                                                                                                                                    | $O(log N)$                                                              |
| **치명적 단점** | 1.  범위 검색 불가: 해시 함수는 Key를 순서 없이 흩뿌려 놓으므로, 정렬 상태가 아님.<br>2.  해시 충돌(Hash Collision): 서로 다른 Key가 같은 해시 값을 가질 경우, 성능이 저하됨.<br>3. Full Scan 비효율: 정렬되어 있지 않아 전체 스캔 시 비효율적 | 특별히 치명적인 단점은 없으며, 가장 범용적으로 우수한 성능을 보임.      |

이것이 바로 MySQL의 `InnoDB` 엔진이나 `PostgreSQL` 같은 대부분의 RDBMS가 기본 인덱스 타입으로 B+ Tree를 채택한 이유입니다. 해시 인덱스는 메모리 기반 데이터베이스(e.g., Redis)나 특정 스토리지 엔진에서 제한적인 용도로 사용되는 경우가 많습니다.

## 2. 인덱스 (Indexes)

이러한 B+ Tree 자료구조를 활용하여 데이터베이스는 **인덱스(Index)**를 구현합니다. 인덱스는 크게 두 종류로 나눌 수 있으며, 이는 마치 책을 찾는 두 가지 방식에 비유할 수 있습니다.

### 클러스터형 인덱스 (Clustered Index) - "영어 사전"

영어 사전은 단어 자체가 알파벳 순서대로 정렬되어 있고, 그 자리에 바로 뜻(데이터)이 함께 있습니다. 이처럼 **데이터의 물리적인 저장 순서가 인덱스의 순서와 동일한 것**이 클러스터형 인덱스입니다. 데이터 자체가 정렬된 상태이므로 테이블당 단 하나만 존재할 수 있으며, MySQL의 `InnoDB` 엔진에서는 `PRIMARY KEY`가 이 역할을 맡습니다.

### 비클러스터형 인덱스 (Non-Clustered Index) - "책 뒤의 찾아보기"

책 본문은 1페이지부터 순서대로 쓰여 있고, 책 뒤의 '찾아보기'에는 특정 키워드가 어느 페이지에 있는지 정리되어 있습니다. 이처럼 **데이터는 그대로 둔 채, 별도의 공간에 인덱스 B+ Tree를 만들어 실제 데이터의 위치(PK 값)를 가리키는 것**이 비클러스터형 인덱스입니다. `name`이나 `email`처럼 자주 조회되는 다른 컬럼들을 위해 여러 개를 생성할 수 있습니다.

이 구조 때문에 비클러스터형 인덱스로 데이터를 조회할 때는, ① 인덱스에서 PK값을 찾고 → ② 그 PK값으로 클러스터형 인덱스를 다시 찾아가는 2단계 과정을 거칩니다.


### 그렇다면, 왜 PK가 클러스터형 인덱스의 기준이 될까?

> MySQL의 `InnoDB` 엔진에서는 테이블에 `PRIMARY KEY`를 지정하면, 그 PK 컬럼을 기준으로 자동으로 클러스터형 인덱스가 생성됩니다. 왜 `InnoDB` 개발자들은 이런 설계를 선택했을까요?

그 이유는 크게 두 가지 장점에서 찾을 수 있습니다.

**1. 조회 성능의 극대화**

`PRIMARY KEY`는 정의상 특정 데이터를 식별하는 가장 기본적인 키입니다. 이 PK 조회의 성능을 극대화하는 것은 매우 중요합니다.

* 만약 PK가 비클러스터형 인덱스(책 뒤의 찾아보기)로 만들어졌다고 상상해 봅시다.
    * '찾아보기'(인덱스)에서 PK 값을 찾는다.
    * 찾아보기에 적힌 '페이지 번호'(데이터의 실제 주소)를 얻는다.
    * 그 페이지 번호를 가지고 '본문'(데이터 파일)으로 가서 실제 데이터를 읽는다. **(디스크 I/O 추가 발생)**

* 하지만 PK가 클러스터형 인덱스(영어 사전)로 만들어지면,
    * '사전'(클러스터형 인덱스)에서 PK 값을 찾는다.
    * 그 자리에 이미 모든 데이터가 있다. **(추가 I/O 없음)**

이 구조적인 차이가 조회 성능에 큰 영향을 미칩니다.

**2. 범위 검색의 효율성**

`PRIMARY KEY`는 보통 순차적으로 증가하는 숫자(e.g., `auto_increment`)인 경우가 많습니다. `WHERE user_id BETWEEN 100 AND 120` 과 같은 범위 검색 쿼리를 실행할 때 클러스터형 인덱스는 막강한 효율을 보여줍니다.

* **클러스터형 인덱스:** `user_id` 100의 위치를 찾기만 하면, 데이터가 이미 물리적으로 정렬되어 있으므로 디스크의 해당 블록부터 순차적으로 쭉 읽기만 하면 됩니다. 이는 디스크의 **순차 읽기(Sequential Read)**를 유발하여 매우 빠릅니다.
* **비클러스터형 인덱스:** 인덱스에서 100부터 120까지의 데이터 주소를 모두 찾은 뒤, 그 주소들을 가지고 데이터 파일의 여기저기 흩어져 있는 위치에 **랜덤하게 접근(Random Access)**해야 합니다. 이는 디스크 성능에 훨씬 큰 부하를 줍니다.

**결론적으로,** PK를 클러스터형 인덱스로 만드는 이유는 단순히 PK 조회 성능을 높이는 것을 넘어, 모든 비클러스터형 인덱스의 성능에도 간접적으로 좋은 영향을 주기 때문입니다. 왜냐하면 모든 비클러스터형 인덱스는 데이터의 실제 주소 대신, 클러스터형 인덱스의 키(PK 값)를 가지고 있기 때문이죠. 효율적인 PK(e.g., 작고 단순한 정수형)를 사용하는 것이 중요한 이유이기도 합니다.

## 3. 쿼리 실행 엔진과 옵티마이저 (Query Executor & Optimizer)

현대의 데이터베이스는 매우 지능적으로 스스로를 최적화합니다. 과거의 데이터베이스가 정해진 규칙에 따라 동작하는 '규칙 기반 옵티마이저'를 사용했다면, 오늘날 대부분의 RDBMS는 **'비용 기반 옵티마이저(Cost-Based Optimizer, CBO)'**를 탑재하고 있습니다. 이는 테이블의 데이터가 얼마나 많은지, 어떤 값들이 주로 분포하는지 등의 통계 정보를 바탕으로, 각 쿼리를 실행하는 데 드는 비용을 다각도로 계산하여 가장 저렴한, 즉 가장 효율적인 실행 계획을 동적으로 선택하는 방식입니다.

따라서 우리가 "어떻게 쿼리를 짜야 DB가 가장 효율적으로 일할까?"를 고민하는 것은, 바로 이 똑똑한 **옵티마이저**가 최상의 선택을 할 수 있도록 정확한 정보를 제공하고 그 선택을 유도하는 과정이라 할 수 있습니다.

우리가 작성한 `SELECT * FROM ...` 이라는 SQL 텍스트를 DB가 이해하고 최적의 실행 경로를 찾는 과정은 크게 3단계로 이루어집니다.

1.  **파서(Parser):** SQL 텍스트의 문법을 검사하고, DB가 이해할 수 있는 자료구조(Parse Tree)로 변환합니다.
2.  **옵티마이저(Optimizer):** DB의 '뇌'입니다. 파스 트리를 기반으로 실행 가능한 수많은 후보 경로를 생성하고, 통계 정보를 바탕으로 각 경로의 예상 비용(Cost)을 계산하여 가장 효율적인 **실행 계획(Execution Plan)**을 최종 선택합니다.
3.  **실행 엔진(Executor):** 옵티마이저가 선택한 실행 계획에 따라 실제 데이터를 디스크에서 가져와 처리하고, 결과를 반환합니다.

### 옵티마이저는 어떻게 최선을 선택하는가?

옵티마이저의 판단 기준은 **'비용(Cost)'**입니다. 이 비용은 주로 디스크 I/O와 CPU 사용 시간을 종합하여 계산됩니다. 그리고 이 비용을 예측하기 위해, 옵티마이저는 테이블과 인덱스에 대한 다음과 같은 **통계 정보**를 활용합니다.

-   테이블의 전체 행(Row) 개수
-   컬럼의 고유한 값 개수 (**카디널리티**, Cardinality)
-   컬럼 값의 분포도 (**히스토그램**) 등

예를 들어, `status` 컬럼에 인덱스가 있는 `users` 테이블에 `SELECT * FROM users WHERE status = 'ACTIVE';` 쿼리를 실행한다고 가정해 봅시다.

-   **상황 A: `users` 테이블 1억 건 중 99%가 `'ACTIVE'`**
    -   옵티마이저의 판단: "인덱스를 읽고, 테이블을 9900만 번 랜덤 I/O로 접근하는 비용은, 그냥 테이블 전체를 한 번 순차적으로 쭉 읽는(Full Table Scan) 비용보다 훨씬 비싸다. **따라서 인덱스를 쓰지 말자.**"
-   **상황 B: `users` 테이블 1억 건 중 0.01%만 `'ACTIVE'`**
    -   옵티마이저의 판단: "인덱스를 사용해서 1만 건만 접근하는 비용이, 테이블 전체 1억 건을 다 읽는 것보다 압도적으로 저렴하다. **따라서 인덱스를 사용하자.**"

이처럼 옵티마이저는 통계 정보를 바탕으로 합리적인 결정을 내립니다.

### 옵티마이저의 속내 엿보기: `EXPLAIN`

개발자는 `EXPLAIN` 명령어를 통해 옵티마이저가 내린 최종 결정, 즉 실행 계획을 직접 확인할 수 있습니다. `SELECT`문 앞에 이 명령어를 붙이면, 쿼리가 실행되지는 않고 계획표만 출력됩니다. 이 계획표의 핵심 컬럼 몇 가지만 알면 쿼리의 건강 상태를 진단할 수 있습니다.

#### `type`: 가장 중요한 진단 지표
테이블에 어떻게 접근했는지를 보여주며, 아래로 갈수록 성능이 저하됩니다. 최소 `range` 이상을 목표로 해야 합니다.
-   **`const`**, **`system`**: PK나 UNIQUE 키로 단 1건의 데이터를 조회하는 최상의 상태.
-   **`eq_ref`**: JOIN 시 PK/UNIQUE 키로 연결되어 항상 1건만 조회되는 상태.
-   **`ref`**: 일반 인덱스(Non-unique)를 사용한 등호(=) 조회.
-   **`range`**: 인덱스를 사용한 범위 검색 (`>`, `<`, `BETWEEN` 등).
-   **`ALL`**: **Full Table Scan**. 인덱스 없이 테이블 전체를 읽는 최악의 상태로, 반드시 피해야 합니다.

#### `key`: 사용된 인덱스
옵티마이저가 실제로 사용하기로 결정한 인덱스의 이름입니다. 이 값이 `NULL`이면 인덱스를 사용하지 못했다는 의미입니다.

#### `rows`: 예상 작업량
옵티마이저가 이 단계를 처리하기 위해 읽을 것으로 예측하는 행(Row)의 수입니다. 이 숫자가 비정상적으로 크다면 쿼리가 비효율적일 가능성이 높습니다.

#### `Extra`: 추가 핵심 정보
옵티마이저의 결정에 대한 중요한 추가 정보입니다.
-   **`Using index`**: (매우 좋음) **'커버링 인덱스'**. 테이블에 접근하지 않고 오직 인덱스 정보만으로 쿼리를 모두 처리한 최상의 상태.
-   **`Using where`**: 스토리지에서 데이터를 가져온 후, 추가적인 `WHERE` 조건으로 필터링했다는 의미. `type`이 `ALL`과 함께 보인다면 매우 비효율적입니다.
-   **`Using filesort`**: (매우 나쁨) 인덱스를 이용해 정렬하지 못하고, 별도의 정렬 작업을 수행했다는 의미. 심각한 성능 저하의 원인입니다.
-   **`Using temporary`**: (매우 나쁨) 쿼리 처리 중 임시 테이블을 생성했다는 의미. `GROUP BY`와 `ORDER BY`가 다른 경우 등에 나타나며 역시 성능 저하의 주범입니다.

결론적으로, 느린 쿼리의 성능을 개선하는 튜닝은, 결국 옵티마이저가 더 좋은 실행 계획을 선택하도록 `EXPLAIN` 명령어로 그 속내를 들여다보고, 인덱스를 조정하거나 쿼리를 수정하는 과정이라 할 수 있습니다.

## 4. 트랜잭션과 동시성 제어 (Transactions & Concurrency)

안정적인 시스템을 구축하기 위해 반드시 알아야 할 개념입니다. 여러 사용자가 동시에 데이터를 읽고 쓸 때, 데이터의 정합성과 무결성을 어떻게 보장할 수 있을까요?

### 트랜잭션과 ACID

**트랜잭션**은 '계좌 이체'처럼 '모두 성공하거나, 모두 실패해야 하는' 논리적인 작업 단위를 의미합니다. 이 트랜잭션은 **ACID**라는 4가지 특성을 통해 신뢰성을 보장합니다.

-   **원자성 (Atomicity):** All or Nothing.
-   **일관성 (Consistency):** 트랜잭션 후에도 데이터베이스의 규칙은 깨지지 않는다.
-   **고립성 (Isolation):** 여러 트랜잭션은 서로에게 영향을 주지 않는다.
-   **지속성 (Durability):** 성공한 트랜잭션의 결과는 영구적으로 저장된다.

### 격리 수준(Isolation Level)과 동시성

고립성(Isolation)은 보통 **잠금(Lock)**으로 구현되는데, 잠금을 너무 강하게 걸면 시스템 전체가 느려지는 동시성 문제가 발생합니다. 이 정합성과 성능 사이의 줄다리기를 위해 DB는 **격리 수준**이라는 옵션을 제공합니다. SQL 표준에 정의된 4가지 레벨을 낮은 순서부터 자세히 알아보겠습니다.

#### Level 0: `READ UNCOMMITTED`
가장 낮은 격리 수준으로, 아직 커밋(Commit)되지 않은 다른 트랜잭션의 변경 내용을 그대로 읽을 수 있습니다. 이는 **'더티 리드(Dirty Read)'**라는 심각한 문제를 야기할 수 있어 거의 사용되지 않습니다. 다른 트랜잭션이 최종적으로 롤백(Rollback)해버리면, 있지도 않았던 '더러운' 데이터를 읽고 잘못된 판단을 하게 되기 때문입니다.

#### Level 1 & 2: 가장 헷갈리는 두 레벨, 전격 비교

대부분의 데이터베이스가 기본값으로 사용하는 `READ COMMITTED`와 `REPEATABLE READ`는 가장 중요한 레벨이자, 그 차이를 이해하기 가장 까다로운 부분이기도 합니다. "둘 다 커밋된 데이터를 읽는 것인데, 무슨 차이가 있는가?"라는 의문이 들 수 있습니다.

결정적인 차이는 **'언제 커밋된 데이터까지를 인정할 것인가'** 하는 **'시간' 또는 '스냅샷'** 의 개념에 있습니다.

> ##### `READ COMMITTED` (Level 1) - "실시간 TV 뉴스 속보"
>
> 이 레벨은 `SELECT` 쿼리가 실행되는 **그 순간에 커밋된 최신 데이터**를 읽습니다.
> - **(T1) 9:00:00** - 내 트랜잭션에서 상품 재고가 **10개**임을 확인합니다.
> - **(T2) 9:00:05** - 다른 사람이 상품 3개를 주문하고 **커밋**합니다. (DB 실제 재고: 7개)
> - **(T1) 9:00:10** - 내가 다시 재고를 `SELECT`합니다. **결과는 7개입니다.**
>
> 한 트랜잭션 내에서 같은 조회를 반복했는데 다른 결과가 나오는 **Non-Repeatable Read(반복 불가능 읽기)**가 발생합니다.

> ##### `REPEATABLE READ` (Level 2) - "오늘 아침에 인쇄된 신문"
>
> 이 레벨은 트랜잭션이 **시작되는 순간의 데이터베이스 상태를 스냅샷**으로 찍어두고, 트랜잭션이 끝날 때까지 오직 그 스냅샷만을 바라봅니다.
> - **(T1) 9:00:00** - 내 트랜잭션이 시작되며, '재고 10개' 상태가 **스냅샷**으로 기록됩니다.
> - **(T1) 9:00:01** - 재고를 `SELECT`하면 스냅샷의 **10개**가 보입니다.
> - **(T2) 9:00:05** - 다른 사람이 상품 3개를 주문하고 **커밋**합니다. (DB 실제 재고: 7개)
> - **(T1) 9:00:10** - 내가 다시 재고를 `SELECT`합니다. 나는 여전히 내 '아침 신문'(스냅샷)을 보고 있으므로, **결과는 여전히 10개입니다.**
>
> 이처럼 스냅샷을 통해 Non-Repeatable Read를 방지합니다. 하지만 이 레벨에서도 다른 트랜잭션이 새로운 데이터를 `INSERT`하는 것은 막지는 못해, 없던 '유령' 데이터가 보이는 **Phantom Read**가 발생할 수 있습니다.

##### `Non-Repeatable Read`와 `Phantom Read`의 근본적인 차이
- **Non-Repeatable Read (UPDATE 문제):** 내가 읽었던 **'바로 그 행'**의 값이 바뀌는 문제입니다. 특정 행에 대한 '레코드 락'이나 'MVCC 버전'으로 비교적 쉽게 막을 수 있습니다.
- **Phantom Read (INSERT 문제):** 내가 조회한 **'검색 조건에 해당하는 범위'** 안으로 새로운 행이 들어오는 문제입니다. 이는 **'존재하지 않는 공간(Gap)'**까지 잠가야 하는 훨씬 복잡하고 어려운 기술(갭 락, Gap Lock)을 필요로 합니다.

#### Level 3: `SERIALIZABLE`
가장 엄격한 격리 수준으로, 트랜잭션을 순서대로 하나씩 처리하는 것과 같이 동작합니다. 앞서 말한 모든 문제(Dirty Read, Non-Repeatable Read, Phantom Read)를 완벽히 방지하지만, 동시성이 극도로 떨어져 성능이 매우 느려지므로 극히 제한적인 상황에서만 사용됩니다.

#### 정리 표
| 격리 수준              | Dirty Read | Non-Repeatable Read | Phantom Read |
| :--------------------- | :--------- | :------------------ | :----------- |
| **`READ UNCOMMITTED`** | 발생       | 발생                | 발생         |
| **`READ COMMITTED`**   | 방지       | 발생                | 발생         |
| **`REPEATABLE READ`**  | 방지       | 방지                | 발생         |
| **`SERIALIZABLE`**     | 방지       | 방지                | 방지         |

## 마무리하며

지금까지 데이터베이스가 데이터를 저장하고(B+ Tree), 찾고(Index), 처리하는(Optimizer) 방식과 데이터의 일관성을 유지하는(Transaction) 원리에 대해 알아보았습니다. 제가 처음에 DB 공부를 결심했던 두 가지 이유, **'DB 설계 능력'**과 **'시스템 성능 향상'**을 위한 가장 근본적인 첫걸음을 뗐다고 생각합니다.

이 지식들을 한번에 본인 것으로 만드는 것은 어려운 일인 것 같습니다. 저또한 아직 완전히 저의 지식이 되었다고 생각하지는 않습니다. 이 내용을 바탕으로 DB에 대한 심층적인 공부를 앞으로 진행하며 다양한 쿼리를 짜보고, 최적화도 진행할 예정입니다.

궁금한 점이 있으시면 언제든 댓글 남겨주세요. 감사합니다.